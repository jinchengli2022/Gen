# 生成
CUDA_VISIBLE_DEVICES=6 python scripts/gen.py --config /home/ljc/Git/Gen_VLA_Adapter/Gen/configs/examples/pouring_water_trajgen.json

# 远程控制
python scripts/manual_collect.py --config /home/ljc/Git/Gen_VLA_Adapter/Gen/configs/examples/pouring_water_trajgen.json --render 

# 训练
data_name=pouringwater_generated
CUDA_VISIBLE_DEVICES=6 torchrun --standalone --nnodes 1 --nproc-per-node 1 vla-scripts/finetune.py \
--vlm_path pretrained_models/prism-qwen25-extra-dinosiglip-224px-0_5b \
--config_file_path pretrained_models/configs \
--data_root_dir /home/ljc/Git/Gen_VLA_Adapter/data/gen/pouring_water_generated/PouringWater \
--dataset_name $data_name \
--run_root_dir outputs \
--use_film False \
--num_images_in_input 2 \
--use_proprio True \
--use_lora True \
--use_fz False \
--use_minivlm True \
--image_aug True \
--num_steps_before_decay 400000 \
--max_steps 400005 \
--save_freq 5000 \
--save_latest_checkpoint_only False \
--merge_lora_during_training True \
--batch_size 4 \
--grad_accumulation_steps 8 \
--learning_rate 2e-4 \
--lora_rank 64 \
--use_pro_version True \
--wandb_entity "jincheng-li2022-xidian-university" \
--wandb_project "$data_name" \
--run_id_note VLA-Adapter--pouringwater_generated--$current_time \
> logs/VLA-Adapter--pouringwater_generated--$current_time.log 2>&1 &

# 数据生成rule-based部分
(1) 平缓移动到待抓取位置 Apporch
(2) 向下移动并抓取 Grasp
(3) 生成轨迹到指定位置（四元数插值）Move
(4) 通过reward标准判断是否成功（保证合法性）Success

改进：
（1）reward标准最好通过VLM给出
（2）Pick&Place任务前期需要经过分段，不同段有不同的生成策略
策略如：四元数插值、直接复制、Reward导向？
（3）终点的统一性与矛盾性
（4）失败的重试机制？负样本？

# 一些细节
（1）考虑到与示范的速度和节奏一致
如果超过了机械臂上限，则需要做速度上限的限制，同时生成后也需要做速度上限的限制。
（2）根据机器人当前位置进行实时更新，而不是完全预设好的轨迹？？？

# RLDS数据写入管道
1.RGB有做翻转？因为OpenGL，这个要搞清楚
2.整套逻辑要弄明白

# 机械臂关节限位读取在这里
self.env_interface.env.robot[0].composite_controller.robot_model.mujoco_model.jnt_range[:6] #因为只有6个自由度
